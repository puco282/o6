import streamlit as st
from openai import OpenAI # Updated import
from PIL import Image
import base64
import io

# OpenAI API í‚¤ ì„¤ì • (Streamlit Secretsì—ì„œ ê°€ì ¸ì˜´)
# Set OpenAI API key (retrieved from Streamlit Secrets)
# Initialize the OpenAI client
client = OpenAI(api_key=st.secrets["openai"]["api_key"])


st.set_page_config(page_title="Pika ì˜ìƒ ì œì‘ GPT ë„ìš°ë¯¸")
st.title("ğŸ¬ Pika ì˜ìƒ ì œì‘ GPT ë„ìš°ë¯¸")

# ì‚¬ì´ë“œë°”ì—ì„œ ì‘ì—… ì„ íƒ
# Select task from sidebar
chat_option = st.sidebar.radio("ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:", [
    "1. ì´ì•¼ê¸° ì ê²€í•˜ê¸°",
    "2. ì´ì•¼ê¸° ë‚˜ëˆ„ê¸°",
    "3. ìºë¦­í„°/ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±",
    "4. ì¥ë©´ë³„ ì˜ìƒ í”„rompt ì ê²€"
])

# ê³µí†µ GPT í˜¸ì¶œ í•¨ìˆ˜
# Common GPT call function
def ask_gpt(messages, model="gpt-4o"):
    # Updated API call using the new client syntax
    response = client.chat.completions.create(
        model=model,
        messages=messages
    )
    return response.choices[0].message.content

# ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (DALLÂ·E ì‚¬ìš©)
# Image generation function (using DALLÂ·E)
def generate_image(prompt):
    # Updated API call using the new client syntax
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        response_format="b64_json"
    )
    # The response structure changed in v1.0.0
    image_data = base64.b64decode(response.data[0].b64_json)
    return Image.open(io.BytesIO(image_data))

# 1. ì´ì•¼ê¸° ì ê²€í•˜ê¸°
# 1. Story Review
if chat_option.startswith("1"):
    st.header("1. ì´ì•¼ê¸° ì ê²€í•˜ê¸°")
    st.markdown("ğŸ’¬ **ëª©í‘œ:** ì—¬ëŸ¬ë¶„ì˜ ì´ì•¼ê¸°ê°€ ì˜ìƒìœ¼ë¡œ ë§Œë“¤ê¸°ì— ì ì ˆí•œì§€ GPTì™€ í•¨ê»˜ ëŒ€í™”í•˜ë©° ì ê²€í•˜ê³  ë‹¤ë“¬ì–´ ë³´ì„¸ìš”.")

    # Initialize chat history for story review
    if "messages_story_review" not in st.session_state:
        st.session_state.messages_story_review = [
            {"role": "system", "content": (
                "ë„ˆëŠ” ì´ˆë“±í•™ìƒì´ ì°½ì‘í•œ ì´ì•¼ê¸°ë¥¼ Pika ì˜ìƒìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì†Œí¬ë¼í…ŒìŠ¤ì‹ ëŒ€í™”í˜• GPT ë„ìš°ë¯¸ì•¼.\n"
                "í•™ìƒì˜ ì´ì•¼ê¸°ë¥¼ ì½ê³ , ì´í•´ë˜ì§€ ì•Šê±°ë‚˜ êµ¬ì²´í™”ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ **í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸**ì„ í†µí•´ í•™ìƒ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê³  ë‹µí•˜ë„ë¡ ìœ ë„í•´.\n"
                "ì§ˆë¬¸ì€ ì£¼ì¸ê³µì˜ ê°ì •ë¿ë§Œ ì•„ë‹ˆë¼, **ì´ì•¼ê¸° ì† ì‚¬ê±´ì´ ì™œ ë°œìƒí–ˆëŠ”ì§€, ì–´ë–¤ ë°°ê²½ì—ì„œ ì¼ì–´ë‚¬ëŠ”ì§€, ì‚¬ê±´ì˜ ì›ì¸ê³¼ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ì§€, ì¸ë¬¼ë“¤ì˜ í–‰ë™ì´ ì´ì•¼ê¸° ì „ê°œì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë“±**ì„ í­ë„“ê²Œ ë‹¤ë¤„ì•¼ í•´.\n"
                "ì´ì•¼ê¸°ì˜ ê¸¸ì´(1~1ë¶„ 30ì´ˆ), êµ¬ì¡°(ë°œë‹¨-ì „ê°œ-ì ˆì •-ê²°ë§), ì–´ìƒ‰í•œ ë¬¸ì¥ ë“± ì „ë°˜ì ì¸ ì ê²€ì´ í•„ìš”í•˜ì§€ë§Œ, ëª¨ë“  í”¼ë“œë°±ì„ í•œ ë²ˆì— ì œê³µí•˜ì§€ ë§ê³  **ëŒ€í™”ì˜ íë¦„ì— ë§ì¶° ì§ˆë¬¸ì„ í†µí•´ ì´ëŒì–´ë‚´ì•¼ í•´.**\n"
                "í•™ìƒì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì„ ì´ì–´ë‚˜ê°€ê³ , ìµœì¢…ì ìœ¼ë¡œ ì´ì•¼ê¸°ê°€ ì¶©ë¶„íˆ êµ¬ì²´í™”ë˜ì—ˆë‹¤ê³  íŒë‹¨ë˜ë©´ ì¢…í•©ì ì¸ ë³´ì™„ ë°©í–¥ì„ ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ ì•ˆë‚´í•´ì¤˜.\n"
                "í•­ìƒ í•™ìƒì˜ ì°½ì˜ì„±ì„ ì¡´ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¥¼ ì‚¬ìš©í•´."
            )}
        ]
        st.session_state.story_input_submitted = False # Flag to check if initial story is submitted

    # Display chat messages from history
    for message in st.session_state.messages_story_review:
        if message["role"] != "system": # Don't display system messages directly
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # Initial story input
    if not st.session_state.story_input_submitted:
        story = st.text_area("ì—¬ëŸ¬ë¶„ì´ ì°½ì‘í•œ ì´ì•¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", key="initial_story_input")
        if st.button("ì´ì•¼ê¸° ì ê²€ ì‹œì‘") and story:
            st.session_state.messages_story_review.append({"role": "user", "content": story})
            st.session_state.story_input_submitted = True
            # Get initial GPT response
            with st.spinner("GPTê°€ ì´ì•¼ê¸°ë¥¼ ì ê²€ ì¤‘ì…ë‹ˆë‹¤..."):
                gpt_response = ask_gpt(st.session_state.messages_story_review)
                st.session_state.messages_story_review.append({"role": "assistant", "content": gpt_response})
            st.rerun() # Changed from st.experimental_rerun() to st.rerun()

    # Chat input for ongoing conversation
    if st.session_state.story_input_submitted:
        if prompt := st.chat_input("GPTì—ê²Œ ë‹µë³€í•˜ê±°ë‚˜ ì¶”ê°€ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”."):
            st.session_state.messages_story_review.append({"role": "user", "content": prompt})
            with st.spinner("GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                gpt_response = ask_gpt(st.session_state.messages_story_review)
                st.session_state.messages_story_review.append({"role": "assistant", "content": gpt_response})
            st.rerun() # Changed from st.experimental_rerun() to st.rerun()

    # Optional: A button to reset the conversation
    if st.session_state.story_input_submitted and st.button("ëŒ€í™” ì´ˆê¸°í™”", key="reset_story_review_chat"):
        st.session_state.messages_story_review = [
            {"role": "system", "content": (
                "ë„ˆëŠ” ì´ˆë“±í•™ìƒì´ ì°½ì‘í•œ ì´ì•¼ê¸°ë¥¼ Pika ì˜ìƒìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì†Œí¬ë¼í…ŒìŠ¤ì‹ ëŒ€í™”í˜• GPT ë„ìš°ë¯¸ì•¼.\n"
                "í•™ìƒì˜ ì´ì•¼ê¸°ë¥¼ ì½ê³ , ì´í•´ë˜ì§€ ì•Šê±°ë‚˜ êµ¬ì²´í™”ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ **í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸**ì„ í†µí•´ í•™ìƒ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê³  ë‹µí•˜ë„ë¡ ìœ ë„í•´.\n"
                "ì§ˆë¬¸ì€ ì£¼ì¸ê³µì˜ ê°ì •ë¿ë§Œ ì•„ë‹ˆë¼, **ì´ì•¼ê¸° ì† ì‚¬ê±´ì´ ì™œ ë°œìƒí–ˆëŠ”ì§€, ì–´ë–¤ ë°°ê²½ì—ì„œ ì¼ì–´ë‚¬ëŠ”ì§€, ì‚¬ê±´ì˜ ì›ì¸ê³¼ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ì§€, ì¸ë¬¼ë“¤ì˜ í–‰ë™ì´ ì´ì•¼ê¸° ì „ê°œì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë“±**ì„ í­ë„“ê²Œ ë‹¤ë¤„ì•¼ í•´.\n"
                "ì´ì•¼ê¸°ì˜ ê¸¸ì´(1~1ë¶„ 30ì´ˆ), êµ¬ì¡°(ë°œë‹¨-ì „ê°œ-ì ˆì •-ê²°ë§), ì–´ìƒ‰í•œ ë¬¸ì¥ ë“± ì „ë°˜ì ì¸ ì ê²€ì´ í•„ìš”í•˜ì§€ë§Œ, ëª¨ë“  í”¼ë“œë°±ì„ í•œ ë²ˆì— ì œê³µí•˜ì§€ ë§ê³  **ëŒ€í™”ì˜ íë¦„ì— ë§ì¶° ì§ˆë¬¸ì„ í†µí•´ ì´ëŒì–´ë‚´ì•¼ í•´.**\n"
                "í•™ìƒì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì„ ì´ì–´ë‚˜ê°€ê³ , ìµœì¢…ì ìœ¼ë¡œ ì´ì•¼ê¸°ê°€ ì¶©ë¶„íˆ êµ¬ì²´í™”ë˜ì—ˆë‹¤ê³  íŒë‹¨ë˜ë©´ ì¢…í•©ì ì¸ ë³´ì™„ ë°©í–¥ì„ ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ ì•ˆë‚´í•´ì¤˜.\n"
                "í•­ìƒ í•™ìƒì˜ ì°½ì˜ì„±ì„ ì¡´ì¤‘í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¥¼ ì‚¬ìš©í•´."
            )}
        ]
        st.session_state.story_input_submitted = False
        st.rerun() # Changed from st.experimental_rerun() to st.rerun()
